import streamlit as st
from PIL import Image
import torch
import cv2
import numpy as np
from ultralytics import YOLO
import time
import os
from datetime import datetime
import pandas as pd
import base64
from io import BytesIO
import plotly.graph_objects as go
import plotly.express as px
import tempfile
import glob
import gc

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å®‰å…¨å¤´ç›”æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸª–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ– session state
if 'all_results' not in st.session_state:
    st.session_state.all_results = []


def image_to_base64(image):
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
    return img_str


# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
    <style>
        .stButton>button {
            width: 100%;
            background-color: #ff4b4b;
            color: white;
        }
        .stButton>button:hover {
            background-color: #ff6b6b;
        }
    </style>
""", unsafe_allow_html=True)


# åŠ è½½æ¨¡å‹
@st.cache_resource
def load_model(model_path):
    return YOLO(model_path)


# æ¨¡å‹é€‰æ‹©
available_models = [f for f in os.listdir('.') if f.endswith('.pt')]
model_path = 'best.pt' if 'best.pt' in available_models else available_models[0] if available_models else None

if not model_path:
    st.error("æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶")
    st.stop()

# ä¸»ç•Œé¢
st.title("ğŸª– å®‰å…¨å¤´ç›”æ£€æµ‹ç³»ç»Ÿ")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.title("âš™ï¸ ç³»ç»Ÿé…ç½®")

    st.markdown("---")

    # æ£€æµ‹æ¨¡å¼é€‰æ‹©
    detection_mode = st.selectbox(
        "é€‰æ‹©æ£€æµ‹æ¨¡å¼",
        ["ğŸ“¸ å•å¼ å›¾ç‰‡æ£€æµ‹", "ğŸ“ æ‰¹é‡å›¾ç‰‡æ£€æµ‹", "ğŸ“‚ æ•°æ®é›†æ–‡ä»¶å¤¹æ£€æµ‹", "ğŸ¥ å®æ—¶è§†é¢‘æ£€æµ‹", "ğŸ“¹ è§†é¢‘æ–‡ä»¶æ£€æµ‹"],
        help="é€‰æ‹©è¦ä½¿ç”¨çš„æ£€æµ‹æ¨¡å¼"
    )

    st.markdown("---")

    # æ¨¡å‹é€‰æ‹©
    selected_models = st.multiselect(
        "é€‰æ‹©è¦æ¯”è¾ƒçš„æ¨¡å‹",
        available_models,
        default=[model_path],
        help="å¯ä»¥é€‰æ‹©å¤šä¸ªæ¨¡å‹è¿›è¡Œæ¯”è¾ƒ"
    )

    if not selected_models:
        selected_models = [model_path]

    confidence = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.01, 0.01)

    # é«˜çº§è®¾ç½®
    with st.expander("é«˜çº§è®¾ç½®"):
        iou_threshold = st.slider("IOUé˜ˆå€¼", 0.0, 1.0, 0.45, 0.01)
        max_det = st.number_input("æœ€å¤§æ£€æµ‹æ•°é‡", 1, 100, 20)

    st.markdown("---")

# åŠ è½½æ‰€æœ‰é€‰ä¸­çš„æ¨¡å‹
models = {name: load_model(name) for name in selected_models}


def show_model_comparison(results_data, model_names, processing_times, confidence_scores, detection_counts):
    """æ˜¾ç¤ºæ¨¡å‹å¯¹æ¯”ç»“æœ"""
    if len(model_names) > 1:
        st.markdown("### æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ")

        # è¡¨æ ¼å±•ç¤º
        comparison_df = pd.DataFrame(results_data)
        st.table(comparison_df.style.highlight_max(subset=['æ£€æµ‹ç›®æ ‡æ•°', 'å¹³å‡é¢„æµ‹ç‡'], color='lightgreen')
                 .highlight_min(subset=['å¤„ç†æ—¶é—´'], color='lightgreen'))

        # å¯è§†åŒ–æ¯”è¾ƒ
        st.markdown("### å¯è§†åŒ–æ¯”è¾ƒ")

        # ä½¿ç”¨ä¸¤åˆ—å¸ƒå±€æ¥æ˜¾ç¤ºå›¾è¡¨
        viz_col1, viz_col2 = st.columns(2)

        with viz_col1:
            # å¤„ç†æ—¶é—´å’Œé¢„æµ‹ç‡æ¯”è¾ƒ
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=model_names,
                y=processing_times,
                name="å¤„ç†æ—¶é—´(ç§’)",
                yaxis="y1"
            ))
            fig.add_trace(go.Bar(
                x=model_names,
                y=[conf * 100 for conf in confidence_scores],
                name="å¹³å‡é¢„æµ‹ç‡(%)",
                yaxis="y2"
            ))
            fig.update_layout(
                title="å¤„ç†æ—¶é—´ vs é¢„æµ‹ç‡",
                yaxis=dict(title="å¤„ç†æ—¶é—´(ç§’)", side="left"),
                yaxis2=dict(title="é¢„æµ‹ç‡(%)", side="right", overlaying="y"),
                showlegend=True
            )
            st.plotly_chart(fig, use_container_width=True)

        with viz_col2:
            # é›·è¾¾å›¾æ¯”è¾ƒ
            max_time = max(processing_times) if processing_times else 1
            max_count = max(detection_counts) if detection_counts else 1
            
            # å¦‚æœmax_countä¸º0ï¼Œå°†å…¶è®¾ç½®ä¸º1ä»¥é¿å…é™¤ä»¥é›¶
            if max_count == 0:
                max_count = 1

            fig_radar = go.Figure()
            for i, model in enumerate(model_names):
                fig_radar.add_trace(go.Scatterpolar(
                    r=[
                        confidence_scores[i] * 100,  # é¢„æµ‹ç‡ç™¾åˆ†æ¯”
                        (1 - processing_times[i] / max_time) * 100,  # å¤„ç†é€Ÿåº¦ï¼ˆå½’ä¸€åŒ–å¹¶åè½¬ï¼‰
                        detection_counts[i] / max_count * 100  # æ£€æµ‹æ•°é‡ï¼ˆå½’ä¸€åŒ–ï¼‰
                    ],
                    theta=['é¢„æµ‹ç‡', 'å¤„ç†é€Ÿåº¦', 'æ£€æµ‹æ•°é‡'],
                    name=model,
                    fill='toself'
                ))

            fig_radar.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 100]
                    )),
                showlegend=True,
                title="æ¨¡å‹ç»¼åˆæ€§èƒ½å¯¹æ¯”"
            )
            st.plotly_chart(fig_radar, use_container_width=True)


def process_image(model, img_array, confidence, iou_threshold, max_det):
    """å¤„ç†å•å¼ å›¾ç‰‡å¹¶è¿”å›ç»“æœ"""
    start_time = time.time()
    
    # ç¡®ä¿å›¾ç‰‡æ˜¯RGBæ ¼å¼
    if len(img_array.shape) == 2:  # å¦‚æœæ˜¯ç°åº¦å›¾
        img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
    elif len(img_array.shape) == 3 and img_array.shape[2] == 4:  # å¦‚æœæ˜¯RGBA
        img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
    
    # ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
    results = model.predict(
        source=img_array,
        conf=confidence,
        iou=iou_threshold,
        max_det=max_det,
        verbose=False
    )[0]
    
    # è·å–å¤„ç†æ—¶é—´
    process_time = time.time() - start_time
    
    # è·å–æ£€æµ‹ç»“æœ
    boxes = results.boxes
    detection_count = len(boxes)
    avg_confidence = float(torch.mean(boxes.conf)) if detection_count > 0 else 0
    
    # åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶æ£€æµ‹æ¡†
    plotted_img = results.plot()
    
    return {
        'image': Image.fromarray(plotted_img),
        'process_time': process_time,
        'detection_count': detection_count,
        'avg_confidence': avg_confidence
    }

def process_dataset_batch(model, image_files, confidence, iou_threshold, max_det, batch_size=32):
    """åˆ†æ‰¹å¤„ç†æ•°æ®é›†å›¾ç‰‡"""
    total_images = len(image_files)
    results_list = []
    
    # åˆ›å»ºè¿›åº¦æ¡
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i in range(0, total_images, batch_size):
        batch_files = image_files[i:i + batch_size]
        batch_results = []
        
        for img_file in batch_files:
            try:
                # è¯»å–å¹¶å¤„ç†å›¾ç‰‡
                img = Image.open(img_file)
                img_array = np.array(img)
                result = process_image(model, img_array, confidence, iou_threshold, max_det)
                
                # æ·»åŠ æ–‡ä»¶ååˆ°ç»“æœä¸­
                result['filename'] = os.path.basename(img_file)
                batch_results.append(result)
                
                # é‡Šæ”¾å†…å­˜
                img.close()
                del img
                del img_array
                
            except Exception as e:
                st.warning(f"å¤„ç†å›¾ç‰‡ {os.path.basename(img_file)} æ—¶å‡ºé”™: {str(e)}")
                continue
        
        # æ›´æ–°è¿›åº¦
        progress = (i + len(batch_files)) / total_images
        progress_bar.progress(progress)
        status_text.text(f"å·²å¤„ç† {i + len(batch_files)}/{total_images} å¼ å›¾ç‰‡")
        
        # å°†æ‰¹æ¬¡ç»“æœæ·»åŠ åˆ°æ€»ç»“æœåˆ—è¡¨
        results_list.extend(batch_results)
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
    
    progress_bar.empty()
    status_text.empty()
    
    return results_list

if detection_mode == "ğŸ“¸ å•å¼ å›¾ç‰‡æ£€æµ‹":
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=['png', 'jpg', 'jpeg'])

    if uploaded_file is not None:
        try:
            # è¯»å–å›¾ç‰‡
            image = Image.open(uploaded_file)
            img_array = np.array(image)

            # åˆ›å»ºå¤šåˆ—å¸ƒå±€æ˜¾ç¤ºä¸åŒæ¨¡å‹çš„ç»“æœ
            num_models = len(models)
            cols = st.columns(min(num_models, 2))
            
            results_data = []
            model_names = []
            processing_times = []
            confidence_scores = []
            detection_counts = []

            # å¤„ç†æ¯ä¸ªæ¨¡å‹
            for idx, (model_name, model) in enumerate(models.items()):
                col_idx = idx % len(cols)
                
                with cols[col_idx]:
                    st.markdown(f"### æ¨¡å‹: {model_name}")
                    
                    # å¤„ç†å›¾ç‰‡
                    result = process_image(model, img_array, confidence, iou_threshold, max_det)
                    
                    # æ˜¾ç¤ºå¤„ç†åçš„å›¾ç‰‡
                    st.image(result['image'], caption=f"æ£€æµ‹ç»“æœ - {model_name}")
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    st.write(f"å¤„ç†æ—¶é—´: {result['process_time']:.3f} ç§’")
                    st.write(f"æ£€æµ‹ç›®æ ‡æ•°: {result['detection_count']}")
                    st.write(f"å¹³å‡é¢„æµ‹ç‡: {result['avg_confidence']*100:.2f}%")
                    
                    # æ”¶é›†æ¯”è¾ƒæ•°æ®
                    results_data.append({
                        'æ¨¡å‹': model_name,
                        'å¤„ç†æ—¶é—´': f"{result['process_time']:.3f}ç§’",
                        'æ£€æµ‹ç›®æ ‡æ•°': result['detection_count'],
                        'å¹³å‡é¢„æµ‹ç‡': f"{result['avg_confidence']*100:.2f}%"
                    })
                    model_names.append(model_name)
                    processing_times.append(result['process_time'])
                    confidence_scores.append(result['avg_confidence'])
                    detection_counts.append(result['detection_count'])
            
            # æ˜¾ç¤ºæ¨¡å‹æ¯”è¾ƒç»“æœ
            show_model_comparison(results_data, model_names, processing_times, confidence_scores, detection_counts)

        except Exception as e:
            st.error(f"å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {str(e)}")

elif detection_mode == "ğŸ“ æ‰¹é‡å›¾ç‰‡æ£€æµ‹":
    # åˆå§‹åŒ– session state
    if 'current_image_index' not in st.session_state:
        st.session_state.current_image_index = 0
    if 'batch_results' not in st.session_state:
        st.session_state.batch_results = None
    if 'last_params' not in st.session_state:
        st.session_state.last_params = None

    uploaded_files = st.file_uploader("é€‰æ‹©å¤šå¼ å›¾ç‰‡", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)

    if uploaded_files:
        # æ£€æŸ¥å‚æ•°æ˜¯å¦å‘ç”Ÿå˜åŒ–
        current_params = f"{confidence}_{iou_threshold}_{max_det}"
        params_changed = current_params != st.session_state.last_params
        
        # å¦‚æœæ˜¯é¦–æ¬¡æ£€æµ‹æˆ–å‚æ•°å‘ç”Ÿå˜åŒ–ï¼Œè¿›è¡Œæ£€æµ‹
        if not st.session_state.batch_results or params_changed:
            st.session_state.last_params = current_params
            st.info(f"å·²ä¸Šä¼  {len(uploaded_files)} å¼ å›¾ç‰‡")

            # å¼€å§‹æ‰¹é‡æ£€æµ‹
            all_results = []
            model_performance = []

            progress_bar = st.progress(0)
            status_text = st.empty()

            for img_idx, img_path in enumerate(uploaded_files):
                try:
                    # æ›´æ–°è¿›åº¦
                    progress = (img_idx + 1) / len(uploaded_files)
                    progress_bar.progress(progress)
                    status_text.text(f"å¤„ç†å›¾ç‰‡ {img_idx+1}/{len(uploaded_files)}")

                    # è¯»å–å›¾ç‰‡
                    image = Image.open(img_path)
                    img_array = np.array(image)

                    # å­˜å‚¨å½“å‰å›¾ç‰‡çš„æ‰€æœ‰æ¨¡å‹ç»“æœ
                    current_results = {
                        'image_name': img_path.name,
                        'results': []
                    }

                    # ä½¿ç”¨æ¯ä¸ªé€‰å®šçš„æ¨¡å‹è¿›è¡Œæ£€æµ‹
                    for model_name, model in models.items():
                        start_time = time.time()
                        result = model(img_array, conf=confidence, iou=iou_threshold, max_det=max_det)
                        end_time = time.time()

                        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                        proc_time = end_time - start_time
                        num_detections = len(result[0].boxes)
                        if num_detections > 0:
                            confidences = [box.conf.cpu().numpy().item() for box in result[0].boxes]
                            avg_conf = sum(confidences) / num_detections
                        else:
                            avg_conf = 0

                        # å­˜å‚¨æ£€æµ‹ç»“æœ
                        current_results['results'].append({
                            'model': model_name,
                            'result': result,
                            'img': result[0].plot(),
                            'detections': num_detections,
                            'confidence': avg_conf,
                            'time': proc_time
                        })

                    all_results.append(current_results)

                    # æ›´æ–°æ¨¡å‹æ€§èƒ½ç»Ÿè®¡
                    if not model_performance:  # é¦–æ¬¡åˆå§‹åŒ–æ€§èƒ½ç»Ÿè®¡
                        model_performance = [{
                            'æ¨¡å‹': model_result['model'],
                            'å¹³å‡æ£€æµ‹æ•°': model_result['detections'],
                            'å¹³å‡é¢„æµ‹ç‡': f"{model_result['confidence']:.2%}",
                            'å¹³å‡å¤„ç†æ—¶é—´': f"{model_result['time']:.3f}ç§’"
                        } for model_result in current_results['results']]
                    else:  # æ›´æ–°ç°æœ‰ç»Ÿè®¡
                        for i, model_result in enumerate(current_results['results']):
                            model_performance[i]['å¹³å‡æ£€æµ‹æ•°'] = (model_performance[i]['å¹³å‡æ£€æµ‹æ•°'] * len(
                                all_results) + model_result['detections']) / (len(all_results) + 1)
                            model_performance[i][
                                'å¹³å‡é¢„æµ‹ç‡'] = f"{(float(model_performance[i]['å¹³å‡é¢„æµ‹ç‡'].strip('%')) * len(all_results) + model_result['confidence'] * 100) / (len(all_results) + 1):.2f}%"
                            model_performance[i][
                                'å¹³å‡å¤„ç†æ—¶é—´'] = f"{(float(model_performance[i]['å¹³å‡å¤„ç†æ—¶é—´'].strip('ç§’')) * len(all_results) + model_result['time']) / (len(all_results) + 1):.3f}ç§’"

                except Exception as e:
                    st.error(f"å¤„ç†å›¾ç‰‡ {img_path.name} æ—¶å‡ºé”™: {str(e)}")

            # æ¸…é™¤è¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬
            progress_bar.empty()
            status_text.empty()

            # ä¿å­˜ç»“æœåˆ° session state
            st.session_state.batch_results = {
                'results': all_results,
                'performance': model_performance
            }
            st.session_state.current_image_index = 0

        # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
        results = st.session_state.batch_results['results']
        model_performance = st.session_state.batch_results['performance']

        # åˆ›å»ºä¸Šä¸€å¼ /ä¸‹ä¸€å¼ æŒ‰é’®
        col1, col2, col3 = st.columns([1, 3, 1])
        with col1:
            if st.button("ä¸Šä¸€å¼ "):
                st.session_state.current_image_index = (st.session_state.current_image_index - 1) % len(results)

        with col2:
            st.markdown(
                f"##### å½“å‰: {st.session_state.current_image_index + 1}/{len(results)} - {results[st.session_state.current_image_index]['image_name']}")

        with col3:
            if st.button("ä¸‹ä¸€å¼ "):
                st.session_state.current_image_index = (st.session_state.current_image_index + 1) % len(results)

        # æ˜¾ç¤ºå½“å‰å›¾ç‰‡çš„æ£€æµ‹ç»“æœ
        current_result = results[st.session_state.current_image_index]

        # åˆ›å»ºå¤šåˆ—å¸ƒå±€æ˜¾ç¤ºä¸åŒæ¨¡å‹çš„ç»“æœ
        num_models = len(current_result['results'])
        if num_models > 2:
            # å¦‚æœæ¨¡å‹æ•°é‡å¤§äº2ï¼Œä½¿ç”¨2åˆ—å¸ƒå±€
            num_cols = 2
            num_rows = (num_models + 1) // 2
            for row in range(num_rows):
                cols = st.columns(num_cols)
                for col_idx in range(num_cols):
                    model_idx = row * num_cols + col_idx
                    if model_idx < num_models:
                        model_result = current_result['results'][model_idx]
                        with cols[col_idx]:
                            st.markdown(f"**{model_result['model']}**")
                            st.image(model_result['img'])
        else:
            # å¦‚æœæ¨¡å‹æ•°é‡å°äºç­‰äº2ï¼Œä½¿ç”¨å•è¡Œå¸ƒå±€
            cols = st.columns(num_models)
            for idx, model_result in enumerate(current_result['results']):
                with cols[idx]:
                    st.markdown(f"**{model_result['model']}**")
                    st.image(model_result['img'])

        # æ˜¾ç¤ºæ¨¡å‹å¯¹æ¯”
        if len(model_performance) > 0:
            results_data = []
            model_names = []
            processing_times = []
            confidence_scores = []
            detection_counts = []
            for model_perf in model_performance:
                model_names.append(model_perf['æ¨¡å‹'])
                detection_counts.append(model_perf['å¹³å‡æ£€æµ‹æ•°'])
                conf = float(model_perf['å¹³å‡é¢„æµ‹ç‡'].strip('%')) / 100
                confidence_scores.append(conf)
                time_val = float(model_perf['å¹³å‡å¤„ç†æ—¶é—´'].strip('ç§’'))
                processing_times.append(time_val)

                results_data.append({
                    "æ¨¡å‹": model_perf['æ¨¡å‹'],
                    "æ£€æµ‹ç›®æ ‡æ•°": model_perf['å¹³å‡æ£€æµ‹æ•°'],
                    "å¹³å‡é¢„æµ‹ç‡": model_perf['å¹³å‡é¢„æµ‹ç‡'],
                    "å¤„ç†æ—¶é—´": model_perf['å¹³å‡å¤„ç†æ—¶é—´']
                })

            show_model_comparison(results_data, model_names, processing_times, confidence_scores, detection_counts)

elif detection_mode == "ğŸ“‚ æ•°æ®é›†æ–‡ä»¶å¤¹æ£€æµ‹":
    dataset_path = st.text_input("è¾“å…¥æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„")
    
    if dataset_path and os.path.isdir(dataset_path):
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_extensions = ['.jpg', '.jpeg', '.png']
        image_files = []
        for ext in image_extensions:
            image_files.extend(glob.glob(os.path.join(dataset_path, f"*{ext}")))
            image_files.extend(glob.glob(os.path.join(dataset_path, f"*{ext.upper()}")))
        
        if not image_files:
            st.warning("æœªåœ¨æŒ‡å®šæ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            st.stop()
        
        # æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯
        st.info(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
        
        # æ‰¹å¤„ç†è®¾ç½®
        with st.expander("æ‰¹å¤„ç†è®¾ç½®"):
            batch_size = st.slider("æ‰¹å¤„ç†å¤§å°", 1, 64, 32, 
                                 help="è¾ƒå¤§çš„æ‰¹å¤„ç†å¤§å°å¯èƒ½ä¼šåŠ å¿«å¤„ç†é€Ÿåº¦ï¼Œä½†ä¼šæ¶ˆè€—æ›´å¤šå†…å­˜")
            
        # åˆ›å»ºç»“æœä¿å­˜ç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = os.path.join(dataset_path, f"results_{timestamp}")
        os.makedirs(results_dir, exist_ok=True)
        
        # å¤„ç†æ¯ä¸ªæ¨¡å‹
        all_model_results = {}
        
        for model_name, model in models.items():
            st.markdown(f"### å¤„ç†æ¨¡å‹: {model_name}")
            
            try:
                # åˆ†æ‰¹å¤„ç†æ•°æ®é›†
                results = process_dataset_batch(
                    model, image_files, confidence, iou_threshold, max_det, batch_size
                )
                
                # ä¿å­˜ç»“æœ
                results_path = os.path.join(results_dir, f"{model_name}_results.csv")
                results_df = pd.DataFrame([{
                    'æ–‡ä»¶å': r['filename'],
                    'æ£€æµ‹ç›®æ ‡æ•°': r['detection_count'],
                    'å¹³å‡é¢„æµ‹ç‡': f"{r['avg_confidence']*100:.2f}%",
                    'å¤„ç†æ—¶é—´(ç§’)': f"{r['process_time']:.3f}"
                } for r in results])
                
                results_df.to_csv(results_path, index=False, encoding='utf-8-sig')
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                st.write("ç»Ÿè®¡ä¿¡æ¯:")
                st.write(f"- æ€»å¤„ç†æ—¶é—´: {sum(r['process_time'] for r in results):.2f} ç§’")
                st.write(f"- å¹³å‡æ¯å¼ å¤„ç†æ—¶é—´: {sum(r['process_time'] for r in results)/len(results):.3f} ç§’")
                st.write(f"- æ€»æ£€æµ‹ç›®æ ‡æ•°: {sum(r['detection_count'] for r in results)}")
                st.write(f"- ç»“æœå·²ä¿å­˜è‡³: {results_path}")
                
                # å­˜å‚¨ç»“æœç”¨äºæ¯”è¾ƒ
                all_model_results[model_name] = results
                
            except Exception as e:
                st.error(f"å¤„ç†æ¨¡å‹ {model_name} æ—¶å‡ºé”™: {str(e)}")
                continue
        
        # å¦‚æœæœ‰å¤šä¸ªæ¨¡å‹ï¼Œæ˜¾ç¤ºæ¯”è¾ƒç»“æœ
        if len(all_model_results) > 1:
            st.markdown("### æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ")
            
            # å‡†å¤‡æ¯”è¾ƒæ•°æ®
            comparison_data = []
            for model_name, results in all_model_results.items():
                total_time = sum(r['process_time'] for r in results)
                avg_time = total_time / len(results)
                total_detections = sum(r['detection_count'] for r in results)
                avg_confidence = sum(r['avg_confidence'] for r in results) / len(results)
                
                comparison_data.append({
                    'æ¨¡å‹': model_name,
                    'æ€»å¤„ç†æ—¶é—´': f"{total_time:.2f}ç§’",
                    'å¹³å‡å¤„ç†æ—¶é—´': f"{avg_time:.3f}ç§’",
                    'æ€»æ£€æµ‹ç›®æ ‡æ•°': total_detections,
                    'å¹³å‡é¢„æµ‹ç‡': f"{avg_confidence*100:.2f}%"
                })
            
            # æ˜¾ç¤ºæ¯”è¾ƒè¡¨æ ¼
            comparison_df = pd.DataFrame(comparison_data)
            st.table(comparison_df)
            
        st.success(f"æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {results_dir}")
        
    else:
        st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„")

elif detection_mode == "ğŸ¥ å®æ—¶è§†é¢‘æ£€æµ‹":
    st.markdown("### å®æ—¶è§†é¢‘æ£€æµ‹")

    # é€‰æ‹©è¦å¯¹æ¯”çš„æ¨¡å‹
    selected_models = st.multiselect(
        "é€‰æ‹©è¦å¯¹æ¯”çš„æ¨¡å‹",
        list(models.keys()),
        default=list(models.keys())[:2] if len(models) > 1 else list(models.keys())
    )

    if len(selected_models) < 1:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨¡å‹")
    else:
        # åˆ›å»ºæ¨¡å‹ç»“æœæ˜¾ç¤ºçš„åˆ—
        model_cols = st.columns(len(selected_models))
        model_displays = {model: col.empty() for model, col in zip(selected_models, model_cols)}
        model_stats = {model: col.empty() for model, col in zip(selected_models, model_cols)}

        # åˆå§‹åŒ–session state
        if 'detection_running' not in st.session_state:
            st.session_state.detection_running = False
        if 'detection_history' not in st.session_state:
            st.session_state.detection_history = []
        if 'current_session' not in st.session_state:
            st.session_state.current_session = {
                'start_time': None,
                'model_performance': {}
            }

        # å¼€å§‹/åœæ­¢æŒ‰é’®
        if not st.session_state.detection_running:
            if st.button("å¼€å§‹æ£€æµ‹", key="start_detection"):
                st.session_state.detection_running = True
                # è®°å½•ä¼šè¯å¼€å§‹æ—¶é—´
                st.session_state.current_session = {
                    'start_time': time.strftime("%Y-%m-%d %H:%M:%S"),
                    'model_performance': {model_name: {
                        'detections': 0,
                        'confidence': 0,
                        'time': 0,
                        'frames': 0
                    } for model_name in selected_models}
                }
                st.rerun()
        else:
            if st.button("åœæ­¢æ£€æµ‹", key="stop_detection"):
                st.session_state.detection_running = False
                # ä¿å­˜å½“å‰ä¼šè¯åˆ°å†å²è®°å½•
                if st.session_state.current_session['model_performance']:
                    session_data = {
                        'session_time': st.session_state.current_session['start_time'],
                        'model_stats': {}
                    }

                    for model_name, perf in st.session_state.current_session['model_performance'].items():
                        frames = perf['frames']
                        if frames > 0:
                            session_data['model_stats'][model_name] = {
                                "å¹³å‡æ£€æµ‹æ•°": f"{perf['detections'] / frames:.1f}",
                                "å¹³å‡é¢„æµ‹ç‡": f"{perf['confidence'] / frames:.2%}",
                                "å¹³å‡å¸§ç‡": f"{1.0 / (perf['time'] / frames):.1f} FPS"
                            }

                    st.session_state.detection_history.append(session_data)
                st.rerun()

        # å¦‚æœæ£€æµ‹æ­£åœ¨è¿è¡Œ
        if st.session_state.detection_running:
            # åˆå§‹åŒ–æ‘„åƒå¤´
            cap = cv2.VideoCapture(0)

            try:
                if not cap.isOpened():
                    st.error("æ— æ³•æ‰“å¼€æ‘„åƒå¤´ï¼Œè¯·æ£€æŸ¥æ‘„åƒå¤´è¿æ¥")
                    st.session_state.detection_running = False
                else:
                    st.success("æ‘„åƒå¤´å·²è¿æ¥")

                    while cap.isOpened() and st.session_state.detection_running:
                        ret, frame = cap.read()
                        if not ret:
                            st.error("æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                            break

                        for idx, model_name in enumerate(selected_models):
                            with model_cols[idx]:
                                model = models[model_name]
                                start_time = time.time()
                                result = model(frame, conf=confidence, iou=iou_threshold, max_det=max_det)
                                proc_time = time.time() - start_time

                                num_detections = len(result[0].boxes)
                                if num_detections > 0:
                                    confidences = [box.conf.item() for box in result[0].boxes]
                                    avg_conf = sum(confidences) / num_detections
                                else:
                                    avg_conf = 0

                                # æ›´æ–°å½“å‰ä¼šè¯çš„æ€§èƒ½ç»Ÿè®¡
                                perf = st.session_state.current_session['model_performance'][model_name]
                                perf['detections'] += num_detections
                                perf['confidence'] += avg_conf
                                perf['time'] += proc_time
                                perf['frames'] += 1

                                # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                                annotated_frame = result[0].plot()
                                model_displays[model_name].image(
                                    annotated_frame,
                                    channels="BGR",
                                    caption=f"{model_name} - å®æ—¶æ£€æµ‹"
                                )

                                # æ›´æ–°å®æ—¶ç»Ÿè®¡
                                current_fps = 1.0 / proc_time if proc_time > 0 else 0
                                stats_text = f"""
                                #### å®æ—¶ç»Ÿè®¡ - {model_name}
                                - æ£€æµ‹ç›®æ ‡æ•°: {num_detections}
                                - é¢„æµ‹ç‡: {avg_conf:.2%}
                                - å¤„ç†å¸§ç‡: {current_fps:.1f} FPS
                                """
                                model_stats[model_name].markdown(stats_text)

                        time.sleep(0.01)

            finally:
                cap.release()

        # æ˜¾ç¤ºå†å²æ£€æµ‹è®°å½•
        if st.session_state.detection_history:
            st.markdown("### å†å²æ£€æµ‹è®°å½•")

            for idx, session in enumerate(reversed(st.session_state.detection_history)):
                st.markdown(f"#### æ£€æµ‹ä¼šè¯ {len(st.session_state.detection_history) - idx}")
                st.markdown(f"å¼€å§‹æ—¶é—´: {session['session_time']}")

                # åˆ›å»ºè¡¨æ ¼æ•°æ®
                table_data = []
                for model_name, stats in session['model_stats'].items():
                    row_data = {"æ¨¡å‹": model_name}
                    row_data.update(stats)
                    table_data.append(row_data)

                # æ˜¾ç¤ºè¡¨æ ¼
                if table_data:
                    st.table(pd.DataFrame(table_data))
                st.markdown("---")

            # æ·»åŠ æ¸…é™¤å†å²è®°å½•çš„æŒ‰é’®
            if st.button("æ¸…é™¤å†å²è®°å½•"):
                st.session_state.detection_history = []
                st.rerun()

elif detection_mode == "ğŸ“¹ è§†é¢‘æ–‡ä»¶æ£€æµ‹":
    st.markdown("### è§†é¢‘æ–‡ä»¶æ£€æµ‹")

    # è§†é¢‘ä¸Šä¼ 
    video_file = st.file_uploader("ä¸Šä¼ è§†é¢‘", type=['mp4', 'avi', 'mov', 'mpeg'])

    if video_file is not None:
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶æ¥ä¿å­˜ä¸Šä¼ çš„è§†é¢‘
        temp_video_path = os.path.join(tempfile.gettempdir(), video_file.name)
        with open(temp_video_path, 'wb') as temp_file:
            temp_file.write(video_file.read())

        # æ˜¾ç¤ºä¸Šä¼ çš„è§†é¢‘ä¿¡æ¯
        video_info = f"è§†é¢‘åç§°: {video_file.name}"
        st.info(video_info)

        # é€‰æ‹©è¦å¯¹æ¯”çš„æ¨¡å‹
        selected_models = st.multiselect(
            "é€‰æ‹©è¦å¯¹æ¯”çš„æ¨¡å‹",
            list(models.keys()),
            default=list(models.keys())[:2] if len(models) > 1 else list(models.keys())
        )

        if len(selected_models) < 1:
            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨¡å‹")
        else:
            # åˆ›å»ºæ€§èƒ½ç»Ÿè®¡å®¹å™¨
            stats_container = st.empty()

            # åˆ›å»ºæ¨¡å‹ç»“æœæ˜¾ç¤ºçš„åˆ—
            model_cols = st.columns(len(selected_models))
            model_displays = {model: col.empty() for model, col in zip(selected_models, model_cols)}
            model_stats = {model: col.empty() for model, col in zip(selected_models, model_cols)}

            if st.button("å¼€å§‹æ£€æµ‹"):
                # åˆå§‹åŒ–è§†é¢‘æ•è·
                cap = cv2.VideoCapture(temp_video_path)

                # è·å–è§†é¢‘ä¿¡æ¯
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                fps = int(cap.get(cv2.CAP_PROP_FPS))

                # åˆå§‹åŒ–æ€§èƒ½ç»Ÿè®¡
                model_performance = {model_name: {
                    'detections': 0,
                    'confidence': 0,
                    'time': 0,
                    'frames': 0
                } for model_name in selected_models}

                # åˆ›å»ºè¿›åº¦æ¡
                progress_bar = st.progress(0)
                frame_counter = 0

                # å¤„ç†è§†é¢‘å¸§
                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret:
                        break

                    frame_counter += 1
                    progress = frame_counter / total_frames
                    progress_bar.progress(progress)

                    # å¯¹æ¯ä¸ªé€‰ä¸­çš„æ¨¡å‹è¿›è¡Œæ£€æµ‹
                    for model_name in selected_models:
                        model = models[model_name]
                        start_time = time.time()
                        result = model(frame, conf=confidence, iou=iou_threshold, max_det=max_det)
                        proc_time = time.time() - start_time

                        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                        num_detections = len(result[0].boxes)
                        if num_detections > 0:
                            confidences = [box.conf.item() for box in result[0].boxes]
                            avg_conf = sum(confidences) / num_detections
                        else:
                            avg_conf = 0

                        # æ›´æ–°æ¨¡å‹æ€§èƒ½ç»Ÿè®¡
                        model_performance[model_name]['detections'] += num_detections
                        model_performance[model_name]['confidence'] += avg_conf
                        model_performance[model_name]['time'] += proc_time
                        model_performance[model_name]['frames'] += 1

                        # åœ¨å¸§ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
                        annotated_frame = result[0].plot()

                        # æ›´æ–°æ˜¾ç¤º
                        model_displays[model_name].image(annotated_frame, channels="BGR", caption=model_name)

                        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                        current_fps = 1.0 / proc_time if proc_time > 0 else 0
                        stats_text = f"""
                        æ£€æµ‹ç›®æ ‡æ•°: {num_detections}
                        å¹³å‡é¢„æµ‹ç‡: {avg_conf:.2%}
                        å¤„ç†å¸§ç‡: {current_fps:.1f} FPS
                        """
                        model_stats[model_name].text(stats_text)

                    # æ›´æ–°æ€»ä½“è¿›åº¦
                    stats_container.text(f"å¤„ç†è¿›åº¦: {frame_counter}/{total_frames} å¸§")

                # é‡Šæ”¾èµ„æº
                cap.release()

                # å¤„ç†å®Œæˆåæ˜¾ç¤ºæ€»ä½“æ€§èƒ½ç»Ÿè®¡å’Œæ¨¡å‹å¯¹æ¯”
                st.success("è§†é¢‘å¤„ç†å®Œæˆï¼")

                # å‡†å¤‡æ¨¡å‹å¯¹æ¯”æ•°æ®
                results_data = []
                model_names = []
                processing_times = []
                confidence_scores = []
                detection_counts = []

                # è®¡ç®—å’Œæ˜¾ç¤ºæ¯ä¸ªæ¨¡å‹çš„å¹³å‡æ€§èƒ½
                st.markdown("### æ¨¡å‹æ€§èƒ½ç»Ÿè®¡")
                for model_name in selected_models:
                    perf = model_performance[model_name]
                    frames = perf['frames']
                    avg_detections = perf['detections'] / frames
                    avg_conf = perf['confidence'] / frames
                    avg_time = perf['time'] / frames
                    avg_fps = 1.0 / avg_time if avg_time > 0 else 0

                    model_names.append(model_name)
                    processing_times.append(avg_time)
                    confidence_scores.append(avg_conf)
                    detection_counts.append(avg_detections)

                    results_data.append({
                        "æ¨¡å‹": model_name,
                        "å¹³å‡æ£€æµ‹æ•°": f"{avg_detections:.1f}",
                        "å¹³å‡é¢„æµ‹ç‡": f"{avg_conf:.2%}",
                        "å¹³å‡å¸§ç‡": f"{avg_fps:.1f} FPS"
                    })

                # æ˜¾ç¤ºè¡¨æ ¼æ¯”è¾ƒ
                st.markdown("#### æ€§èƒ½æ•°æ®å¯¹æ¯”")
                df = pd.DataFrame(results_data)
                st.table(df)

                # æ˜¾ç¤ºå›¾è¡¨å¯¹æ¯”
                st.markdown("#### æ€§èƒ½æŒ‡æ ‡å¯è§†åŒ–")

                # å¤„ç†æ—¶é—´å¯¹æ¯”
                fig_time = go.Figure()
                for model_name, proc_time in zip(model_names, processing_times):
                    fig_time.add_trace(go.Bar(name=model_name, x=['å¤„ç†æ—¶é—´'], y=[proc_time]))
                fig_time.update_layout(title="å¹³å‡å¤„ç†æ—¶é—´å¯¹æ¯”", yaxis_title="ç§’")
                st.plotly_chart(fig_time)

                # é¢„æµ‹ç‡å¯¹æ¯”
                fig_conf = go.Figure()
                for model_name, conf in zip(model_names, confidence_scores):
                    fig_conf.add_trace(go.Bar(name=model_name, x=['é¢„æµ‹ç‡'], y=[conf]))
                fig_conf.update_layout(title="å¹³å‡é¢„æµ‹ç‡å¯¹æ¯”", yaxis_title="é¢„æµ‹ç‡")
                st.plotly_chart(fig_conf)

                # æ£€æµ‹æ•°é‡å¯¹æ¯”
                fig_det = go.Figure()
                for model_name, dets in zip(model_names, detection_counts):
                    fig_det.add_trace(go.Bar(name=model_name, x=['æ£€æµ‹æ•°'], y=[dets]))
                fig_det.update_layout(title="å¹³å‡æ£€æµ‹æ•°å¯¹æ¯”", yaxis_title="æ•°é‡")
                st.plotly_chart(fig_det)

                # é›·è¾¾å›¾å¯¹æ¯”
                fig_radar = go.Figure()
                for model_name, proc_time, conf, dets in zip(model_names, processing_times, confidence_scores,
                                                             detection_counts):
                    # å½’ä¸€åŒ–æ•°æ®
                    max_time = max(processing_times)
                    max_dets = max(detection_counts)
                    normalized_time = 1 - (proc_time / max_time)  # åè½¬ï¼Œä½¿å¾—æ›´å¿«çš„å¤„ç†æ—¶é—´å¾—åˆ†æ›´é«˜
                    normalized_dets = dets / max_dets

                    fig_radar.add_trace(go.Scatterpolar(
                        r=[normalized_time, conf, normalized_dets],
                        theta=['å¤„ç†é€Ÿåº¦', 'é¢„æµ‹ç‡', 'æ£€æµ‹æ•°'],
                        name=model_name,
                        fill='toself'
                    ))

                fig_radar.update_layout(
                    polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
                    title="æ¨¡å‹æ€§èƒ½é›·è¾¾å›¾"
                )
                st.plotly_chart(fig_radar)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.remove(temp_video_path)
                except:
                    pass
    else:
        st.info("è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶ (æ”¯æŒæ ¼å¼: MP4, AVI, MOV, MPEG)")

st.markdown("---")
st.markdown(" ç¬¬äºŒå°ç»„ | " + datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
